{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Block-wise viewing of an Image\n",
    "Stough, DIP\n",
    "\n",
    "Through spatial filtering we have been looking at ways of understanding the local neighborhood of a pixel. We saw that a low-pass spatial filter such as a Gaussian can give us some kind of weighted average of the local neighborhood, while the high-pass (e.g., Laplacian) tells us the degree to which a pixel is on an edge, or the edginess of the neighborhood. \n",
    "\n",
    "## Block Transforms\n",
    "To simplify our studies, we're going to start splitting up the image into non-overlapping square blocks. That way, instead of having a different local neighborhood for each pixel, we'll now have every pixel within a block sharing the local neighborhood. Let's see what we mean.\n",
    "\n",
    "- [View as blocks](https://scikit-image.org/docs/dev/api/skimage.util.html#skimage.util.view_as_blocks)\n",
    "- [Montage](https://scikit-image.org/docs/0.7.0/api/skimage.util.montage.html#)\n",
    "- [Online example of usage](https://scikit-image.org/docs/dev/auto_examples/numpy_operations/plot_view_as_blocks.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.util import view_as_blocks\n",
    "from skimage.util import montage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normImage(I):\n",
    "    I = I.copy() - I.min()\n",
    "    I = I/I.max()\n",
    "    return I\n",
    "\n",
    "def arrInfo(I):\n",
    "    return I.shape, I.min(), I.max(), I.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an image\n",
    "I = plt.imread('candy.png')\n",
    "arrInfo(I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "## Split the image into 8x8x3 blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_shape = (8, 8, 3)\n",
    "view = view_as_blocks(I, block_shape=block_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll reshape the view so we can process the blocks in a single dimension.\n",
    "view = np.squeeze(view)\n",
    "\n",
    "blockView = view.reshape([view.shape[0]*view.shape[1]] + list(view.shape[2:]))\n",
    "print(blockView.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "## Let's replace each block with its mean color\n",
    "Study the below loop. I know I said we'd avoid looping over pixels, but I kind of lied. Here, we're looping over 8x8 blocks, which is okay :-P\n",
    "\n",
    "Think about how we can compute almost anything about a block inside this loop, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newImageBlocks = np.zeros(blockView.shape)\n",
    "\n",
    "for i, block in enumerate(blockView):\n",
    "    bT = np.mean(block, axis=(0,1)) # Some transform of the block\n",
    "    # bT is a (3,) array of the average color of the block\n",
    "    # This line sets each of the 8x8 pixels to be the (1,1,3) version of the bT\n",
    "    newImageBlocks[i][:] = np.reshape(bT, (1,1,3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use montage to put the blocks back together.\n",
    "I_mean = montage(newImageBlocks, grid_shape=[view.shape[0], view.shape[1]], multichannel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrInfo(I_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "## Visualize the image and its mean reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1,2, figsize=(7,3), sharex=True, sharey=True)\n",
    "ax[0].imshow(I)\n",
    "ax[0].set_title('Original Image')\n",
    "ax[1].imshow(I_mean)\n",
    "ax[1].set_title('Mean Reconstruction')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "## Characterizing the information in a block \n",
    "In the above we've replaced the 64 colors within a block with just one color. But then, if you don't zoom in too much, notice that we didn't lose a lot of what matters about the image. In fact, if you could keep just one piece of information about a block, you could do a lot worse than the mean. \n",
    "\n",
    "In fact what we just did is 64:1 lossy compression of the image. That's great, but with quite a bit of loss. Maybe we could keep more information in places where it matters, and less in places where it doesn't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
